---
title: "Using News and Market Data to Predict Stock Movements"
course: "DATS 6101 Introduction to Data Science"
authors: "Mary Gibbs and Peter Riley"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Packages
```{r}
library(bestglm)
library(car)
library(caret)
library(corrplot)
library(dplyr)
library(ggplot2)
library(ISLR)
library(MASS)
library(Metrics)
library(pROC)
library(pscl)
library(rattle)
library(RColorBrewer)
library(ResourceSelection)
library(rpart)
library(rpart.plot)
library(ROCR)
library(tree)
library(verification)
```

Data 
```{r}
#read in data 
df <- read.csv("data/data.csv") 
#remove X column
df$X <- NULL 
#check data
str(df)
#change data types
df$binary_result <- as.factor(df$binary_result)
df$sentimentClass <- as.factor(df$sentimentClass)
df$urgency <- as.factor(df$urgency)
#check data
str(df)
head(df)
```

Multicollinearity
```{r}
#correlation matrix
dfCorrMatrix <- cor(df[, c(4:7, 11:13, 15:18)], method = "pearson")
#correlation plot 
corrplot(dfCorrMatrix, method = "square", addCoef.col = "black", number.cex = 7/ncol(df))
#create df w/o highly correlated features
dfLogModel <- df[, c(4:5, 8:16)]
```

Test/Train
```{r}
#get 80% train
train <- dfLogModel[1:11088, ]
#get 20% test
test <- dfLogModel[11089:13860, ]
```

Full Logistic Regression Model 
```{r}
#full model 
fullModel <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = "logit"), data = train)

#full model summary
summary(fullModel)
#volume and open are statistically significant (p-value < 0.05), contribute to model
#null deviance is 15345 and residual deviance is 15233, terrible reduction
#AIC is 15281

#full model VIF
vif(fullModel)
#VIF < 5, no multicollinearity issues
```

Stepwise Logistic Regression Model
```{r}
#stepwise model
stepModel <- fullModel %>% stepAIC(trace = TRUE)

#stepwise model summary
summary(stepModel)
#volume and open are statistically significant (p-value < 0.05), contribute to model
#null deviance is 15345 and residual deviance is 15237, terrible reduction
#AIC is 15271

#stepwise model VIF
vif(stepModel)
#VIF < 5, no multicollinearity issues
```

Prediction
```{r}
#stepwise model predicition
stepModelPrediction <- predict(stepModel, newdata = test, type = "response")
```

Hit Rate
```{r}
#stepwise model hit rate
stepModelPerLike <- ifelse(stepModelPrediction > 0.5, 1, 0)
stepModelHitRate <- mean(stepModelPerLike == test$binary_result)
stepModelHitRate
#stepwise model hit rate is 47.40%, terrible
```

ROC Curve
```{r}
#stepwise model ROC curve
stepModelROCpred <- prediction(stepModelPrediction, test$binary_result)
stepModelROCperf <- performance(stepModelROCpred, measure = "tpr", x.measure = "fpr")
plot(stepModelROCperf, xlab = "false positive rate", ylab = "true positive rate")
#stepwise model ROC curve is terrible

#stepwise model AUC
bestModelAUC <- performance(bestModelROCpred, measure = "auc")
bestModelAUC
#stepwise model AUC is 0.4967, terrible
```

Decision Tree
```{r}
#build model
tree.results <- rpart(binary_result ~ time+sentimentClass+sentimentNegative+sentimentNeutral+sentimentPositive+bodySize+wordCount, data = training, control= rpart.control(cp=.005), method = "class")

plot(tree.results, uniform=TRUE, margin=.05)
text(tree.results)
summary(tree.results)
# Draw the decision tree using fancyRpart and text tree
fancyRpartPlot(tree.results)

plot(tree.results, uniform=TRUE, margin=.05)
text(tree.results)
#make predictions
tree_pred<- predict(tree.results, newdata=dfTest, type="class")

#misclassification table (the (0, 0) (1,1) diagonals are the correct classifications)
with(dfTest, table(tree_pred, binary_result))

#using the table, we'll find the error 
error_value<-  (1021+629)/ 2771
error_value
```
