par(mfrow = c(1, 2))
#boxplots of total revenue (no outliers) and total expenditure (no outliers)
boxplot(df$total_revenue, main = "Total Revenue (No Outliers)", ylab = "USD (millions)")
boxplot(df$total_expenditure, main = "Total Expenditure (No Outliers)", ylab = "USD (millions)")
#total revenue and total expenditure have no outliers
#divide graph area into three columns
par(mfrow = c(1, 3))
#density plots of total revenue, total expenditure, and 8th grade average math scores
plot(density(df$total_revenue), main = "Total Revenue", xlab = "USD (millions)", ylab = "Frequency", col = "darkolivegreen3")
polygon(density(df$total_revenue), col = "darkolivegreen3")
plot(density(df$total_expenditure), main = "Total Expenditure", xlab = "USD (millions)", ylab = "Frequency", col = "deepskyblue2")
polygon(density(df$total_expenditure), col = "deepskyblue2")
plot(density(df$avg_score), main = "8th Grade Average Math Scores", xlab = "Average Score", ylab = "Frequency", col = "darkorchid3")
polygon(density(df$avg_score), col = "darkorchid3")
#total revenue and total expenditure have slight left skew, 8th grade average math scores looks normally distributed
#Shapiro-Wilk normality test
shapiro.test(df$total_revenue)
shapiro.test(df$total_expenditure)
shapiro.test(df$avg_score)
#total revenue, total expenditure, and 8th grade average math scores have p values < 0.05, not normally distributed
#scatter plot
ggplot(df, aes(x = total_expenditure, y = avg_score)) +
geom_point(shape = 1) +
geom_smooth(method = lm, se = FALSE, color = "goldenrod1") +
ggtitle("8th Grade Average Math Scores vs. Total Expenditure") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Total Expenditure (USD (millions))") +
ylab("Average Score")
#linearity
#covariance matrix
df_cov <- cov(df[, 3:5], method = "pearson")
df_cov
#correlation matrix
df_cor <- cor(df[, 3:5], method = "pearson")
df_cor
#correlation plot
corrplot(df_cor, method = "square", addCoef.col = "black", number.digits = 4)
#all relationships are positive
#strong positive relationship between total revenue and total expenditure
#weak positive relationships between total revenue and 8th grade average math scores and total expenditure and 8th grade average math scores
#model
df_lm <- lm(avg_score ~ total_expenditure, data = df)
summary(df_lm)
#residuals - not normally distributed
#coefficients - total_expenditure p-value < 0.05, statistically significant relationship between education expenditure and 8th grade average math scores
#adjusted R-squared - 3.59% of the variance in 8th grade average math scores can be explained by education expenditure, poor model
#model assumptions
par(mfrow = c(2, 2))
plot(df_lm)
df_lm_res <- df_lm$residuals
describe(df_lm_res)
shapiro.test(df_lm_res)
#linearity - linearity, scatterplot shows linearity, residual vs fitted plot shows residuals skewed to left and spread around nearly horizontal line
#independence of residuals - independence of residuals, observations are independent
#normality of residuals - no normality of residuals, normal Q-Q plot shows that residuals follow straight line well, Shapiro-Wilk normality test shows p value < 0.05
#homoscedasticity of residuals - possible homoscedasticity of residuals, residual vs fitted plot shows residuals skewed to left and spread around slightly negatively sloped line
library(corrplot)
library(data.table)
library(dplyr)
library(ggfortify)
library(ggplot2)
library(ggvis)
library(grid)
library(plyr)
library(psych)
library(stats)
library(VIM)
finances <- fread("finances.csv")
scores <- fread("scores.csv")
str(finances)
str(scores)
#choose columns of interest
finances <- finances[, c(1, 2, 4, 8)]
#join finances and scores on year and state
df <- merge(finances, scores, by = c("YEAR", "STATE"))
#make column names lowercase
df <- setnames(df, tolower(names(df)))
#select 2005-2015
df <- df[df$year > 2004 & df$year < 2016]
#get total revenue in USD (millions)) and total expenditure in USD (millions)
df$total_revenue <- df$total_revenue/1000000
df$total_expenditure <- df$total_expenditure/1000000
#remove rows with avg_score = "-", avg_score = "‡"
df <- df[df$avg_score != "—" & df$avg_score != "‡"]
#select mathematics
df <- df[df$test_subject == 'Mathematics']
#select 8th grade
df <- df[df$test_year == 8]
#change year, state, avg_score, and test_year data types
df$year <- as.factor(df$year)
df$state <- as.factor(df$state)
df$avg_score <- as.numeric(df$avg_score, digits = 7)
df$test_year <- as.character(df$test_year)
#check data frame
str(df)
#get total revenue sum, total expenditure sum, and 8th grade average math scores sum from 2005-2015
df_tr_te_sum <- aggregate(list(df$total_revenue, df$total_expenditure), by = list(df$year), FUN = sum)
colnames(df_tr_te_sum) <- c("year", "total_revenue_sum", "total_expenditure_sum")
df_tr_te_sum <- melt(df_tr_te_sum, id.vars = "year")
df_avg_score_sum <- aggregate(list(df$avg_score), by = list(df$year), FUN = sum)
colnames(df_avg_score_sum) <- c("year", "avg_score_sum")
df_avg_score_sum <- melt(df_avg_score_sum, id.vars = "year")
#line plot of total revenue sum, total expenditure sum, and 8th grade average math scores sum from 2005-2015
ggplot(df_tr_te_sum, aes(x = year, y = value, group = variable, colour = variable)) +
geom_line() +
ggtitle ("Total Revenue Sum and Total Expenditure Sum") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Year") +
ylab("USD (millions)") +
labs(color = "Variable") +
scale_color_manual(values = c("darkolivegreen3", "deepskyblue2"))
ggplot(df_avg_score_sum, aes(x = year, y = value, group = variable, colour = variable)) +
geom_line() +
ggtitle ("8th Grade Average Math Scores Sum") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Year") +
ylab("Average Scores Sum") +
labs(color = "Variable") +
scale_color_manual(values = c("darkorchid3"))
#get sum of total revenue - total expenditure from 2005-2015
df$tr_minus_te <- df$total_revenue - df$total_expenditure
df_sum_tr_minus_te <- aggregate(list(df$tr_minus_te), by = list(df$year), FUN = sum)
colnames(df_sum_tr_minus_te) <- c("year", "sum_total_revenue-total_expenditure")
df_sum_tr_minus_te <- melt(df_sum_tr_minus_te, id.vars = "year")
#line plot of sum of total revenue - total expenditure from 2005-2015
ggplot(df_sum_tr_minus_te, aes(x = year, y = value, group = variable, colour = variable)) +
geom_line() +
ggtitle ("Sum of Total Revenue - Total Expenditure") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Year") +
ylab("USD (millions)") +
labs(color = "Variable") +
scale_color_manual(values = c("darkorange2"))
#describe data frame
describe(df[, 3:5])
#summarize data frame
summary(df)
#divide graph area into three columns
par(mfrow = c(1, 3))
#boxplots of total revenue, total expenditure, and 8th grade average math scores
boxplot(df$total_revenue, main = "Total Revenue", ylab = "USD (millions)")
boxplot(df$total_expenditure, main = "Total Expenditure", ylab = "USD (millions)")
boxplot(df$avg_score, main = "8th Grade Average Math Scores", ylab = "Average Score")
#total revenue and total expenditure have outliers
#remove total revenue and total expenditure outliers
tr_outliers <- boxplot(df$total_revenue, plot = FALSE)$out
te_outliers <- boxplot(df$total_expenditure, plot = FALSE)$out
df <- df[!df$total_expenditure %in% c(tr_outliers, te_outliers)]
#divide graph area into three columns
par(mfrow = c(1, 2))
#boxplots of total revenue (no outliers) and total expenditure (no outliers)
boxplot(df$total_revenue, main = "Total Revenue (No Outliers)", ylab = "USD (millions)")
boxplot(df$total_expenditure, main = "Total Expenditure (No Outliers)", ylab = "USD (millions)")
#total revenue and total expenditure have no outliers
#divide graph area into three columns
par(mfrow = c(1, 3))
#density plots of total revenue, total expenditure, and 8th grade average math scores
plot(density(df$total_revenue), main = "Total Revenue", xlab = "USD (millions)", ylab = "Frequency", col = "darkolivegreen3")
polygon(density(df$total_revenue), col = "darkolivegreen3")
plot(density(df$total_expenditure), main = "Total Expenditure", xlab = "USD (millions)", ylab = "Frequency", col = "deepskyblue2")
polygon(density(df$total_expenditure), col = "deepskyblue2")
plot(density(df$avg_score), main = "8th Grade Average Math Scores", xlab = "Average Score", ylab = "Frequency", col = "darkorchid3")
polygon(density(df$avg_score), col = "darkorchid3")
#total revenue and total expenditure have slight left skew, 8th grade average math scores looks normally distributed
#Shapiro-Wilk normality test
shapiro.test(df$total_revenue)
shapiro.test(df$total_expenditure)
shapiro.test(df$avg_score)
#total revenue, total expenditure, and 8th grade average math scores have p values < 0.05, not normally distributed
#scatter plot
ggplot(df, aes(x = total_expenditure, y = avg_score)) +
geom_point(shape = 1) +
geom_smooth(method = lm, se = FALSE, color = "goldenrod1") +
ggtitle("8th Grade Average Math Scores vs. Total Expenditure") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Total Expenditure (USD (millions))") +
ylab("Average Score")
#linearity
#covariance matrix
df_cov <- cov(df[, 3:5], method = "pearson")
df_cov
#correlation matrix
df_cor <- cor(df[, 3:5], method = "pearson")
df_cor
#correlation plot
corrplot(df_cor, method = "square", addCoef.col = "black", number.digits = 4)
#all relationships are positive
#strong positive relationship between total revenue and total expenditure
#weak positive relationships between total revenue and 8th grade average math scores and total expenditure and 8th grade average math scores
#model
df_lm <- lm(avg_score ~ total_expenditure, data = df)
summary(df_lm)
#residuals - not normally distributed
#coefficients - total_expenditure p-value < 0.05, statistically significant relationship between education expenditure and 8th grade average math scores
#adjusted R-squared - 3.59% of the variance in 8th grade average math scores can be explained by education expenditure, poor model
#model assumptions
par(mfrow = c(2, 2))
plot(df_lm)
df_lm_res <- df_lm$residuals
describe(df_lm_res)
shapiro.test(df_lm_res)
#linearity - linearity, scatterplot shows linearity, residual vs fitted plot shows residuals skewed to left and spread around nearly horizontal line
#independence of residuals - independence of residuals, observations are independent
#normality of residuals - no normality of residuals, normal Q-Q plot shows that residuals follow straight line well, Shapiro-Wilk normality test shows p value < 0.05
#homoscedasticity of residuals - possible homoscedasticity of residuals, residual vs fitted plot shows residuals skewed to left and spread around slightly negatively sloped line
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ResourceSelection)
library(pROC)
library(pscl)
library(ISLR)
library(dplyr)
library(ROCR)
library(bestglm)
library(openintro)
# Chunk 3
#read in data
data <- email
#check data
str(email)
#ensure variable classified correctly
data$to_multiple <- as.factor(data$to_multiple)
data$cc <- as.numeric(data$cc)
data$viagra <- as.factor(data$viagra)
data$format <- as.factor(data$format)
data$re_subj <- as.factor(data$re_subj)
data$exclaim_subj <- as.factor(data$exclaim_subj)
data$spam <- as.factor(data$spam)
#check data
str(data)
# Chunk 4
#logistic regression
#features: to_multiple, cc, attach, dollar, winner, inherit, viagra, password, format, re_subj, and exclaim_subj
#response: spam
spamlogit1 <- glm(spam ~ to_multiple + cc + attach + dollar + winner + inherit + viagra + password + format + re_subj + exclaim_subj, family = binomial(link = 'logit'), data = data)
#results
summary.glm(spamlogit1)
#to_multiple, attach, dollar, winner, inherit, password, format, and re_subj are statistically significant (p-value < 0.05), contribute to model
#null deviance is 2437.2 and residual deviance is 1931.5, not a great reduction
#AIC is 1955.5
#convert results to %
exp(coef(spamlogit1))
# Chunk 5
#get 80% train
train <- data[1:3137, ]
#get 20% test
test <- data[3138:3921,  ]
# Chunk 6
#logistic regression
#features: to_multiple, attach, dollar, winner, inherit, password, format, and re_subj
#response: spam
spamlogit2 <- glm(spam ~ to_multiple + attach + dollar + winner + inherit + password + format + re_subj, family = binomial(link = 'logit'), data = train)
#results
summary(spamlogit2)
#to_multiple, attach, winner, password, format, and re_subj are statistically significant (p-value < 0.05), contribute to model
#null deviance is 1729.6 and residual deviance is 1338.0, not a great reduction
#AIC is 1356, better than model 1
#convert results to %
exp(coef(spamlogit2))
# Chunk 7
#logistic regression
#features: to_multiple, attach, winner, password, format, and re_subj
#response: spam
spamlogit3 <- glm(spam ~ to_multiple + attach + winner + password + format + re_subj, family = binomial(link = 'logit'), data = train)
#results
summary(spamlogit3)
#to_multiple, attach, winner, password, format, and re_subj are statistically significant (p-value < 0.05), contribute to model
#null deviance is 1729.6 and residual deviance is 1343.6, not a great reduction
#AIC is 1357.6, better than model 1, worse than model 2
#convert results to %
exp(coef(spamlogit3))
# Chunk 8
#model 2 prediction
predict_spamlogit2 <- predict.glm(spamlogit2, test, type = 'response')
# Chunk 9
#model 2 hit rate
per_like_spamlogit2 <- ifelse(predict_spamlogit2 > 0.5, 1, 0)
hit_rate_spamlogit2 <- mean(per_like_spamlogit2 == test$spam)
hit_rate_spamlogit2
#model 2 hit rate is 85.20%, okay
#model 2 ROC curve
roc_spamlogit2 <- prediction(predict_spamlogit2, test$spam)
perf_roc_spamlogit2 <- performance(roc_spamlogit2, measure = 'tpr', x.measure = 'fpr')
plot(perf_roc_spamlogit2)
#model 2 ROC curve is okay
#model 2 AUC
perf_auc_spamlogit2 <- performance(roc_spamlogit2, measure = 'auc')
perf_auc_spamlogit2
#model 2 AUC is 0.76, okay
#model 2 is okay at predicting spam
logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
library(ResourceSelection)
library(pROC)
library(pscl)
library(ISLR)
library(dplyr)
library(ROCR)
library(bestglm)
library(openintro)
library(caret)
library(ggplot2)
library(verification)
library(corrplot)
library(car)
#read in data
df <- read.csv("data/data.csv")
#remove X column
df$X <- NULL
#check data
str(df)
#change data types
df$binary_result <- as.factor(df$binary_result)
df$sentimentClass <- as.factor(df$sentimentClass)
df$urgency <- as.factor(df$urgency)
#check data
str(df)
head(df)
#correlation matrix
df_corr_matrix <- cor(df[, c(4:7, 11:13, 15:18)], method = "pearson")
#correlation plot
corrplot(df_corr_matrix, method = "square", addCoef.col = "black", number.cex = 7/ncol(df))
#create df w/o correlated features
df_log_model <- df[, c(4:5, 8:16)]
#get 80% train
train <- df_log_model[1:11088, ]
#get 20% test
test <- df_log_model[11089:13860, ]
#full model
full_model <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = 'logit'), data = train)
summary(full_model)
vif(full_model)
#best model
colnames(train) <- c("volume", "open", "y", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize")
best_train <- train[, c("volume", "open", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize", "y")]
logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
logres.bglm$BestModels
summary(logres.bglm$BestModel)
setwd("~/Documents/GitHub/R/DATS 6101 Project 2")
library(ResourceSelection)
library(pROC)
library(pscl)
library(ISLR)
library(dplyr)
library(ROCR)
library(bestglm)
library(openintro)
library(caret)
library(ggplot2)
library(verification)
library(corrplot)
library(car)
#read in data
df <- read.csv("data/data.csv")
#remove X column
df$X <- NULL
#check data
str(df)
#change data types
df$binary_result <- as.factor(df$binary_result)
df$sentimentClass <- as.factor(df$sentimentClass)
df$urgency <- as.factor(df$urgency)
#check data
str(df)
head(df)
#correlation matrix
df_corr_matrix <- cor(df[, c(4:7, 11:13, 15:18)], method = "pearson")
#correlation plot
corrplot(df_corr_matrix, method = "square", addCoef.col = "black", number.cex = 7/ncol(df))
#create df w/o correlated features
df_log_model <- df[, c(4:5, 8:16)]
#get 80% train
train <- df_log_model[1:11088, ]
#get 20% test
test <- df_log_model[11089:13860, ]
#full model
full_model <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = 'logit'), data = train)
summary(full_model)
vif(full_model)
#best model
colnames(train) <- c("volume", "open", "y", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize")
best_train <- train[, c("volume", "open", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize", "y")]
logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
logres.bglm$BestModels
summary(logres.bglm$BestModel)
#logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
#logres.bglm$BestModels
#summary(logres.bglm$BestModel)
best_model <- glm(binary_result ~ volume + open + provider + sentimentNegative + firstMentionSentence, family = binomial(link = "logit", data = train))
#logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
#logres.bglm$BestModels
#summary(logres.bglm$BestModel)
best_model <- glm(binary_result ~ volume + open + provider + sentimentNegative + firstMentionSentence, family = binomial(link = "logit"), data = train)
# Chunk 1
library(ResourceSelection)
library(pROC)
library(pscl)
library(ISLR)
library(dplyr)
library(ROCR)
library(bestglm)
library(openintro)
library(caret)
library(ggplot2)
library(verification)
library(corrplot)
library(car)
# Chunk 2
#read in data
df <- read.csv("data/data.csv")
#remove X column
df$X <- NULL
#check data
str(df)
#change data types
df$binary_result <- as.factor(df$binary_result)
df$sentimentClass <- as.factor(df$sentimentClass)
df$urgency <- as.factor(df$urgency)
#check data
str(df)
head(df)
# Chunk 3
#correlation matrix
df_corr_matrix <- cor(df[, c(4:7, 11:13, 15:18)], method = "pearson")
#correlation plot
corrplot(df_corr_matrix, method = "square", addCoef.col = "black", number.cex = 7/ncol(df))
#create df w/o correlated features
df_log_model <- df[, c(4:5, 8:16)]
#get 80% train
train <- df_log_model[1:11088, ]
#get 20% test
test <- df_log_model[11089:13860, ]
#full model
full_model <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = "logit"), data = train)
summary(full_model)
vif(full_model)
#best model
#colnames(train) <- c("volume", "open", "y", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize")
#best_train <- train[, c("volume", "open", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize", "y")]
#logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
#logres.bglm$BestModels
#summary(logres.bglm$BestModel)
best_model <- glm(binary_result ~ volume + open + provider + sentimentNegative + firstMentionSentence, family = binomial(link = "logit"), data = train)
#best model
#colnames(train) <- c("volume", "open", "y", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize")
#best_train <- train[, c("volume", "open", "provider", "sentimentClass", "sentimentNegative", "sentimentNeutral", "sentimentPositive", "urgency", "firstMentionSentence", "bodySize", "y")]
#logres.bglm <- bestglm(Xy = best_train, family = binomial, IC = "AIC", method = "exhaustive")
#logres.bglm$BestModels
#summary(logres.bglm$BestModel)
best_model <- glm(binary_result ~ volume + open + provider + sentimentNegative + firstMentionSentence, family = binomial(link = "logit"), data = train)
vif(best_model)
summary(best_model)
len(df)
count(df)
count(df)*.80
[count(df)*.80][0]
#get 80% train
train <- df_log_model[1:count(df)*.80, ]
#get 80% train
train <- df_log_model[1:11088, ]
View(df)
View(df)
bestModelPrediction <- predict(bestModel, newdata = test, type = "response")
#best model - based on commented out due to run time
bestModel <- glm(binary_result ~ volume + open + provider + sentimentNegative + firstMentionSentence, family = binomial(link = "logit"), data = train)
bestModelPrediction <- predict(bestModel, newdata = test, type = "response")
#best model prediction probability distribution
data.frame(preds = bestModelPrediction) %>%
ggplot(aes(x = preds)) +
geom_histogram(bins = 50) +
labs(title = 'Histogram of Predictions') +
theme_bw()
#best model hit rate
bestModelPerLike <- ifelse(bestModelPrediction > 0.5, 1, 0)
bestModelHitRate <- mean(bestModel == test$binary_result)
bestModelHitRate
bestModelHitRate <- mean(bestModel == test$binary_result)
bestModelHitRate
bestModelHitRate <- mean(bestModelPerLike == test$binary_result)
bestModelHitRate
summary(fullModel)
#full model
fullModel <- glm(binary_result ~ volume + open + provider + sentimentClass + sentimentNegative + sentimentNeutral + sentimentPositive + urgency + firstMentionSentence + bodySize, family = binomial(link = "logit"), data = train)
summary(fullModel)
vif(fullModel)
#best model summary
summary(bestModel)
#best model VIF
vif(bestModel)
#best model ROC curve
bestModelROCpred <- prediction(bestModelPrediction, test$binary_result)
bestModelROCplot <- performance(bestModelROCpred, measure = 'tpr', x.measure = 'fpr')
plot(bestModelROCplot)
plot(bestModelROCperf, xlab = "false positive rate", ylab = "true positive rate")
bestModelROCperf <- performance(bestModelROCpred, measure = "tpr", x.measure = "fpr")
plot(bestModelROCperf, xlab = "false positive rate", ylab = "true positive rate")
#CHECK THIS PART, best model prediction probability distribution
data.frame(preds = bestModelPrediction) %>%
ggplot(aes(x = preds)) +
geom_histogram(bins = 50) +
labs(title = "histogram of predictions") +
theme_bw()
#CHECK THIS PART, best model prediction probability distribution
data.frame(predictions = bestModelPrediction) %>%
ggplot(aes(x = predictions)) +
geom_histogram(bins = 50) +
labs(title = "histogram of predictions") +
theme_bw()
bestModelAUC
#best model AUC
bestModelAUC <- performance(bestModelROCpred, measure = "auc")
bestModelAUC
